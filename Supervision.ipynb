{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPju4wqjGWiczO90fgHH2ry"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zG40nOKBo80c","executionInfo":{"status":"ok","timestamp":1732284611938,"user_tz":-60,"elapsed":2687,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}},"outputId":"8f3e0a13-828a-4a97-f4d0-f3f215918b3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting supervision\n","  Downloading supervision-0.25.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.3.1)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n","Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.8.0)\n","Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.26.4)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n","Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.2)\n","Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n","Downloading supervision-0.25.0-py3-none-any.whl (181 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/181.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: supervision\n","Successfully installed supervision-0.25.0\n"]}],"source":["!pip install supervision"]},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gXJKcIhapCxv","executionInfo":{"status":"ok","timestamp":1732284618779,"user_tz":-60,"elapsed":6844,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}},"outputId":"88d8087d-78e4-4a4a-bcb0-ce8e90b9e561"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.36-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.36-py3-none-any.whl (887 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.3/887.3 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.36 ultralytics-thop-2.0.12\n"]}]},{"cell_type":"code","source":["!pip install opencv-python\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYkDTOcTpVT3","executionInfo":{"status":"ok","timestamp":1732284624845,"user_tz":-60,"elapsed":6072,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}},"outputId":"a4e99c7d-b6f5-411d-e32f-201d8062df71"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"]}]},{"cell_type":"code","source":["import cv2\n","from ultralytics import YOLO\n","\n","model = YOLO(\"yolov3u.pt\")\n","image = cv2.imread(\"desk.jpg\")\n","results = model(image)[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jhaXgiFCpYlR","executionInfo":{"status":"ok","timestamp":1732284646470,"user_tz":-60,"elapsed":21650,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}},"outputId":"514667b1-06d7-4136-d6e5-7066e838ab91"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov3u.pt to 'yolov3u.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 198M/198M [00:00<00:00, 225MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ 'source' is missing. Using 'source=/usr/local/lib/python3.10/dist-packages/ultralytics/assets'.\n","\n","image 1/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x480 5 persons, 1 bus, 1 fire hydrant, 101.6ms\n","image 2/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 1 tie, 59.8ms\n","Speed: 5.6ms preprocess, 80.7ms inference, 342.3ms postprocess per image at shape (1, 3, 384, 640)\n"]}]},{"cell_type":"code","source":["import supervision as sv\n","import cv2\n","from ultralytics import YOLO\n","\n","\n","def detect(img_path):\n","  image = cv2.imread(img_path)\n","  results = model(image)[0]\n","  detections = sv.Detections.from_ultralytics(results)\n","  box_annotator = sv.BoxAnnotator()\n","  label_annotator = sv.LabelAnnotator()\n","\n","  # Add bounding boxes\n","  annotated_image = box_annotator.annotate(\n","    scene=image, detections=detections)\n","  # Add labels\n","  annotated_image = label_annotator.annotate(\n","    scene=annotated_image, detections=detections)\n","  return annotated_image"],"metadata":{"id":"OJGFPsLNy9Fb","executionInfo":{"status":"ok","timestamp":1732284646471,"user_tz":-60,"elapsed":25,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import timeit\n","import pandas as pd\n","import numpy as np\n","\n","def benchmark_detect(detect_function, img_path, number=500, repeat=7):\n","    \"\"\"\n","    Benchmarks the detect function by measuring the execution time over a number of iterations.\n","    Returns a list of execution times in milliseconds.\n","    \"\"\"\n","    times = timeit.repeat(\n","        stmt='detect(\"desk.jpg\")',\n","        setup='from __main__ import detect',\n","        repeat=repeat,  # Number of times the timing loop is repeated\n","        number=number   # Number of executions per timing loop\n","    )\n","    # Convert total time to per-execution time in milliseconds\n","    per_execution_times = [t / number * 1000 for t in times]\n","    return per_execution_times\n","\n","number = 10\n","\n","repeat = 100  # Number of times the timing loop is repeated\n","\n","# Run the benchmark\n","execution_times = benchmark_detect(detect, \"desk.jpg\", number=number, repeat=repeat)\n","\n","# Replace 'FrameworkName' with the actual name of the framework\n","framework_name = 'Supervision'\n","\n","df = pd.DataFrame({\n","    'Framework': [framework_name] * len(execution_times),\n","    'ExecutionTime': execution_times\n","})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6G8mkq2EwWy","executionInfo":{"status":"ok","timestamp":1732284755325,"user_tz":-60,"elapsed":85046,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}},"outputId":"a9f65a3c-9cc4-467f-d059-11917ee7191d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 68.4ms\n","Speed: 3.0ms preprocess, 68.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 68.3ms\n","Speed: 2.6ms preprocess, 68.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 68.2ms\n","Speed: 2.9ms preprocess, 68.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 45.0ms\n","Speed: 2.6ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 43.8ms\n","Speed: 3.3ms preprocess, 43.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 42.1ms\n","Speed: 3.9ms preprocess, 42.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 41.5ms\n","Speed: 3.7ms preprocess, 41.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 40.7ms\n","Speed: 3.0ms preprocess, 40.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 2.9ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.5ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.4ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 2.9ms preprocess, 36.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 39.5ms\n","Speed: 3.5ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.1ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 2.5ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 2.4ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.9ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 2.7ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.3ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 2.3ms preprocess, 33.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.3ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.4ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.3ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.0ms preprocess, 35.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 2.8ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.5ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 4.0ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.2ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 4.7ms preprocess, 35.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 4.3ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.7ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 2.6ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 2.5ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.7ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.5ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.6ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.9ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.3ms preprocess, 34.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.5ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 4.5ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.7ms preprocess, 35.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.4ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.9ms\n","Speed: 3.4ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.8ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.5ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.5ms preprocess, 34.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.0ms preprocess, 34.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.3ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 4.0ms preprocess, 35.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.8ms\n","Speed: 2.8ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.8ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.1ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.5ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.5ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.5ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.3ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.9ms\n","Speed: 3.9ms preprocess, 33.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.0ms\n","Speed: 3.6ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.9ms\n","Speed: 3.6ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 2.5ms preprocess, 35.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.0ms\n","Speed: 3.1ms preprocess, 33.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.1ms preprocess, 34.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.9ms preprocess, 34.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.5ms\n","Speed: 3.5ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.4ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.1ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 3.4ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 2.9ms preprocess, 34.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.2ms preprocess, 34.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.0ms\n","Speed: 3.0ms preprocess, 33.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 4.0ms preprocess, 34.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 3.2ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.5ms preprocess, 34.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.8ms\n","Speed: 3.1ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.3ms preprocess, 34.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.5ms\n","Speed: 3.0ms preprocess, 33.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.1ms preprocess, 34.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 3.3ms preprocess, 34.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 3.4ms preprocess, 33.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.9ms preprocess, 35.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.8ms preprocess, 35.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.0ms preprocess, 35.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 6.1ms preprocess, 35.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.1ms preprocess, 35.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.0ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 2.3ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 2.5ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.5ms preprocess, 35.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 2.9ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.3ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.9ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.6ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 4.0ms preprocess, 36.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 4.0ms preprocess, 36.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 2.9ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 3.4ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.5ms preprocess, 34.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 3.3ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.6ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.5ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.3ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.0ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 4.5ms preprocess, 34.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.0ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.0ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.6ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.8ms\n","Speed: 2.6ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 4.7ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.4ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 2.9ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 40.6ms\n","Speed: 3.8ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 2.9ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.3ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.1ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.4ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.9ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.8ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 2.9ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.7ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.7ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.8ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 2.5ms preprocess, 36.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 2.6ms preprocess, 37.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 3.8ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 2.6ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.6ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.6ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.8ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 4.7ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.7ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 2.7ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.6ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.3ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.8ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.6ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.3ms preprocess, 34.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 2.6ms preprocess, 36.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.3ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 2.9ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.6ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 2.7ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.7ms preprocess, 35.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 2.7ms preprocess, 34.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.8ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.4ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 3.3ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.4ms preprocess, 34.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.0ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 2.6ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.2ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 2.6ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.5ms\n","Speed: 2.6ms preprocess, 33.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.8ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.4ms preprocess, 35.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 4.4ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.6ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.7ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.4ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.7ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.0ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.6ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.7ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.0ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 2.6ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.9ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.7ms preprocess, 35.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.0ms preprocess, 34.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.1ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 2.7ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.6ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.5ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.3ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 2.6ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.6ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.7ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 2.9ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 2.7ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.8ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.8ms preprocess, 35.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.8ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 4.3ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 2.8ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.9ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.1ms preprocess, 35.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.8ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 2.7ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 2.7ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.4ms\n","Speed: 2.7ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 3.2ms preprocess, 37.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.6ms\n","Speed: 2.8ms preprocess, 37.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 3.1ms preprocess, 37.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.7ms\n","Speed: 3.0ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.3ms preprocess, 35.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.1ms preprocess, 34.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 3.0ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 2.9ms preprocess, 36.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.1ms preprocess, 34.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.9ms\n","Speed: 3.0ms preprocess, 33.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 5.4ms preprocess, 34.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.2ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.4ms preprocess, 34.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.3ms preprocess, 34.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.4ms preprocess, 34.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.3ms preprocess, 36.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 2.9ms preprocess, 36.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.0ms preprocess, 36.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.1ms\n","Speed: 4.0ms preprocess, 37.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.0ms preprocess, 36.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.0ms preprocess, 36.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.8ms\n","Speed: 2.9ms preprocess, 36.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.0ms preprocess, 36.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.3ms preprocess, 36.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.4ms preprocess, 35.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.4ms preprocess, 36.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.4ms preprocess, 34.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 3.2ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 2.9ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.8ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.8ms\n","Speed: 3.7ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.1ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.8ms\n","Speed: 3.1ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.1ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.8ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.5ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 3.0ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.1ms\n","Speed: 4.0ms preprocess, 38.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 3.2ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.0ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.9ms preprocess, 35.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.3ms\n","Speed: 3.1ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.3ms\n","Speed: 2.9ms preprocess, 38.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 2.9ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.9ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 2.8ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.8ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.1ms preprocess, 35.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.1ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.8ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 2.8ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 2.7ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 2.8ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 2.6ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 5.8ms preprocess, 35.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.0ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.9ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.2ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 4.2ms preprocess, 34.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.0ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 2.7ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.1ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.8ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.0ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 2.8ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.4ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.6ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.9ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.0ms preprocess, 34.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.7ms preprocess, 35.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.0ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.7ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.8ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.9ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 2.9ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.1ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.6ms\n","Speed: 3.0ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.8ms preprocess, 35.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.3ms preprocess, 34.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.6ms\n","Speed: 3.6ms preprocess, 33.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 45.4ms\n","Speed: 9.3ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.2ms preprocess, 35.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 2.7ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.1ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.0ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.6ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.6ms\n","Speed: 2.7ms preprocess, 37.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.3ms\n","Speed: 2.9ms preprocess, 38.3ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 39.2ms\n","Speed: 2.9ms preprocess, 39.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 71.1ms\n","Speed: 24.1ms preprocess, 71.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 42.5ms\n","Speed: 3.0ms preprocess, 42.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.9ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.8ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 2.8ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.9ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 2.9ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.0ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 42.2ms\n","Speed: 2.9ms preprocess, 42.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.4ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.4ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.0ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.8ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 3.0ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 2.8ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.4ms\n","Speed: 2.9ms preprocess, 37.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.6ms\n","Speed: 2.9ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 2.9ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 2.9ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.0ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 4.0ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.0ms preprocess, 35.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.4ms\n","Speed: 2.9ms preprocess, 37.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.0ms\n","Speed: 3.5ms preprocess, 38.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 2.9ms preprocess, 37.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.8ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 2.8ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 2.8ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 2.8ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.8ms\n","Speed: 3.0ms preprocess, 37.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.9ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.9ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.9ms preprocess, 35.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 4.5ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.1ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.0ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.0ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.9ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 3.1ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.1ms\n","Speed: 2.8ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 2.9ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.9ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.1ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.9ms preprocess, 35.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.1ms preprocess, 35.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.1ms\n","Speed: 6.2ms preprocess, 38.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.1ms preprocess, 35.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.1ms preprocess, 35.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.3ms preprocess, 34.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.0ms preprocess, 34.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.0ms preprocess, 34.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.1ms preprocess, 34.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.0ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.9ms preprocess, 35.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 2.9ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.3ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.0ms preprocess, 36.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.1ms preprocess, 34.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.2ms preprocess, 35.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.1ms preprocess, 36.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 5.1ms preprocess, 35.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.0ms preprocess, 35.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.5ms preprocess, 35.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.0ms preprocess, 35.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.4ms preprocess, 36.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.8ms preprocess, 35.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.2ms preprocess, 37.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.5ms\n","Speed: 3.3ms preprocess, 37.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 3.0ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.8ms\n","Speed: 3.4ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 3.0ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.2ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.4ms\n","Speed: 3.0ms preprocess, 37.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 2.9ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.8ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.3ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.1ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.8ms\n","Speed: 3.0ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 2.9ms preprocess, 36.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 5.0ms preprocess, 34.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 4.2ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.5ms preprocess, 35.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.7ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 4.0ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.2ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.0ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.1ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 3.4ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.5ms\n","Speed: 3.1ms preprocess, 37.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.4ms\n","Speed: 3.0ms preprocess, 37.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.5ms\n","Speed: 3.4ms preprocess, 37.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.5ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.8ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.0ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.6ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.0ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.1ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.5ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 2.8ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.2ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.9ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.4ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 2.9ms preprocess, 34.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 4.1ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 4.0ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.3ms preprocess, 35.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 2.9ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 3.0ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.5ms preprocess, 35.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.8ms\n","Speed: 3.5ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.6ms preprocess, 35.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.0ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.6ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 4.2ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.3ms preprocess, 35.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.2ms preprocess, 35.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.2ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 2.7ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.2ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 2.8ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.1ms preprocess, 36.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.1ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.4ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.8ms\n","Speed: 3.4ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 2.9ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.1ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.0ms preprocess, 34.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.1ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.1ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.0ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 4.3ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.0ms preprocess, 35.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.1ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.3ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.0ms preprocess, 35.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 5.1ms preprocess, 35.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.2ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 4.7ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.9ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.0ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 4.6ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.8ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.9ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.8ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.9ms\n","Speed: 3.1ms preprocess, 33.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.1ms preprocess, 34.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.3ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.2ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.1ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.0ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.3ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.8ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 2.9ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 2.8ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 4.6ms preprocess, 35.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.7ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.3ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.9ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.0ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 2.9ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 4.1ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 41.9ms\n","Speed: 3.6ms preprocess, 41.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.0ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.8ms\n","Speed: 4.1ms preprocess, 37.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.7ms\n","Speed: 3.5ms preprocess, 38.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.7ms\n","Speed: 3.2ms preprocess, 37.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 3.0ms preprocess, 34.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.9ms preprocess, 35.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 3.2ms preprocess, 34.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.3ms\n","Speed: 3.1ms preprocess, 33.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.1ms preprocess, 34.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 2.9ms preprocess, 33.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.8ms\n","Speed: 3.1ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.5ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.2ms preprocess, 35.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.1ms preprocess, 35.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 5.5ms preprocess, 34.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.0ms preprocess, 35.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 6.2ms preprocess, 34.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 4.1ms preprocess, 34.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.3ms preprocess, 35.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 2.8ms preprocess, 34.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.1ms preprocess, 35.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 2.9ms preprocess, 34.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.0ms preprocess, 34.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.0ms preprocess, 36.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 2.9ms preprocess, 36.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.0ms preprocess, 35.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.9ms preprocess, 35.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 4.4ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 2.9ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.7ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.8ms\n","Speed: 3.0ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.0ms preprocess, 36.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.0ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.9ms\n","Speed: 2.7ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.8ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.8ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.0ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.5ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 2.9ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 2.9ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.8ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 2.9ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.0ms preprocess, 35.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.7ms preprocess, 36.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.0ms preprocess, 34.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.0ms preprocess, 34.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.3ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.1ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 3.0ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.0ms\n","Speed: 3.2ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 2.8ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 8.2ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.8ms preprocess, 35.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.1ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 4.2ms preprocess, 36.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 4.1ms preprocess, 36.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.0ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.5ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.1ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.4ms\n","Speed: 2.9ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.5ms\n","Speed: 3.0ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.7ms\n","Speed: 3.0ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.9ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.6ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.0ms\n","Speed: 3.0ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 2.8ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.3ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 4.0ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 2.9ms preprocess, 34.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.0ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.0ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.1ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.6ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.0ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.8ms\n","Speed: 3.2ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.2ms preprocess, 35.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.2ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.4ms\n","Speed: 2.9ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 3.0ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.6ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.0ms preprocess, 34.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.0ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.3ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.2ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 2.9ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.5ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.8ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 2.9ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.7ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 4.0ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.4ms preprocess, 35.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.9ms preprocess, 35.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 2.9ms preprocess, 36.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.3ms preprocess, 35.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.8ms\n","Speed: 3.1ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.7ms\n","Speed: 3.0ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 3.0ms preprocess, 37.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 4.0ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.8ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.9ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.0ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 2.9ms preprocess, 35.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 6.3ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.0ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.0ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.8ms\n","Speed: 3.3ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 2.8ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 2.9ms preprocess, 35.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 2.8ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.6ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.4ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.2ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.0ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.1ms\n","Speed: 3.3ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 4.9ms preprocess, 35.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.0ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.1ms preprocess, 36.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.5ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 4.5ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 2.9ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.1ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.3ms preprocess, 36.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 3.3ms preprocess, 33.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.1ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.4ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.2ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.1ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 3.4ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.1ms\n","Speed: 4.8ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.5ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.9ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.8ms\n","Speed: 2.9ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.5ms\n","Speed: 3.8ms preprocess, 38.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.9ms\n","Speed: 3.7ms preprocess, 38.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.8ms\n","Speed: 6.9ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.6ms\n","Speed: 3.2ms preprocess, 38.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.8ms\n","Speed: 3.3ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.8ms\n","Speed: 3.1ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.6ms\n","Speed: 3.1ms preprocess, 38.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.6ms\n","Speed: 3.0ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.2ms preprocess, 36.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.9ms preprocess, 35.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 4.3ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.1ms preprocess, 36.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.1ms preprocess, 36.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 4.6ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.7ms preprocess, 36.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.0ms preprocess, 36.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.9ms preprocess, 35.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.9ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.2ms preprocess, 35.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 4.9ms preprocess, 35.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 3.1ms preprocess, 37.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.0ms preprocess, 36.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.8ms\n","Speed: 3.0ms preprocess, 37.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 3.3ms preprocess, 37.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.9ms\n","Speed: 3.0ms preprocess, 38.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.3ms\n","Speed: 2.9ms preprocess, 38.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.3ms\n","Speed: 3.1ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.0ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.1ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.9ms\n","Speed: 3.0ms preprocess, 38.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.2ms\n","Speed: 4.1ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.9ms\n","Speed: 3.0ms preprocess, 38.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.3ms\n","Speed: 3.1ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.6ms\n","Speed: 3.0ms preprocess, 38.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.1ms\n","Speed: 3.2ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.1ms\n","Speed: 3.5ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.7ms\n","Speed: 3.0ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 2.9ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 2.6ms preprocess, 37.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.1ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 2.9ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.1ms\n","Speed: 3.6ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.5ms\n","Speed: 4.2ms preprocess, 37.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.6ms\n","Speed: 3.6ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.0ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 5.4ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.0ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 2.8ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.1ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 4.4ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.6ms preprocess, 35.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 2.9ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 2.9ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.8ms\n","Speed: 2.8ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.3ms\n","Speed: 3.5ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.6ms\n","Speed: 3.2ms preprocess, 37.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.0ms preprocess, 35.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 5.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 2.9ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 4.6ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.7ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.4ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.4ms preprocess, 35.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.0ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.6ms preprocess, 36.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.6ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.7ms preprocess, 35.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 2.9ms preprocess, 34.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.6ms\n","Speed: 3.0ms preprocess, 38.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.4ms\n","Speed: 3.4ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.8ms\n","Speed: 3.1ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 3.0ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.0ms\n","Speed: 3.3ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 42.9ms\n","Speed: 3.0ms preprocess, 42.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.0ms preprocess, 36.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.1ms\n","Speed: 3.6ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 3.1ms preprocess, 36.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 2.9ms preprocess, 35.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.1ms preprocess, 35.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.0ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.3ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.0ms preprocess, 36.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.2ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.2ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.2ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.3ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 2.9ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.3ms preprocess, 34.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.2ms preprocess, 36.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 5.6ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 2.9ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.5ms\n","Speed: 3.0ms preprocess, 37.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.1ms\n","Speed: 3.6ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.1ms\n","Speed: 3.0ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.2ms\n","Speed: 2.9ms preprocess, 38.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.0ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.0ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.3ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.5ms\n","Speed: 3.2ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.8ms\n","Speed: 5.5ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 2.8ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.9ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 2.9ms preprocess, 35.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.2ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.4ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 4.2ms preprocess, 35.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 2.8ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.4ms preprocess, 35.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.0ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.7ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.0ms preprocess, 36.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.5ms\n","Speed: 3.6ms preprocess, 35.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 2.9ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.4ms\n","Speed: 3.1ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.2ms\n","Speed: 3.0ms preprocess, 38.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.9ms\n","Speed: 3.1ms preprocess, 37.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.0ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.2ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.3ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 2.9ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 4.1ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.9ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.1ms\n","Speed: 3.0ms preprocess, 37.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 5.0ms preprocess, 35.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.1ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.0ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 2.9ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.1ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.5ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.2ms preprocess, 36.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.8ms\n","Speed: 2.9ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.1ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.1ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 2.9ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.0ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.0ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 2.9ms preprocess, 36.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.0ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.1ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.0ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.6ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.9ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 2.8ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 4.6ms preprocess, 36.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 5.0ms preprocess, 35.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.2ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 3.2ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.5ms\n","Speed: 3.3ms preprocess, 36.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.2ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.1ms preprocess, 36.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.0ms preprocess, 34.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 2.9ms preprocess, 34.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 5.5ms preprocess, 35.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.9ms\n","Speed: 3.2ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.1ms preprocess, 35.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.7ms\n","Speed: 3.1ms preprocess, 33.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 3.2ms preprocess, 35.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.1ms preprocess, 35.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.2ms preprocess, 34.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.2ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.1ms preprocess, 34.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.2ms preprocess, 34.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.2ms preprocess, 34.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.2ms preprocess, 35.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.0ms preprocess, 35.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.0ms preprocess, 35.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 5.0ms preprocess, 35.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.0ms preprocess, 34.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 3.8ms preprocess, 35.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 2.7ms preprocess, 35.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.1ms\n","Speed: 4.4ms preprocess, 35.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.9ms preprocess, 35.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 4.0ms preprocess, 36.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.1ms preprocess, 34.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.6ms\n","Speed: 3.7ms preprocess, 37.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.7ms\n","Speed: 3.8ms preprocess, 38.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 3.4ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.0ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.7ms\n","Speed: 4.4ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.1ms\n","Speed: 3.0ms preprocess, 37.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 5.3ms preprocess, 36.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 2.9ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.1ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.6ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.1ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.1ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 4.1ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 40.7ms\n","Speed: 3.4ms preprocess, 40.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.3ms\n","Speed: 3.0ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 39.0ms\n","Speed: 3.0ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 39.3ms\n","Speed: 3.0ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 39.2ms\n","Speed: 4.6ms preprocess, 39.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 4.6ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.4ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.0ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.0ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.6ms\n","Speed: 2.9ms preprocess, 35.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.4ms\n","Speed: 3.2ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.1ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 2.9ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.0ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.1ms preprocess, 36.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.4ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.7ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 4.5ms preprocess, 36.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.0ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.4ms preprocess, 35.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.2ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.0ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.4ms\n","Speed: 3.6ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.2ms preprocess, 35.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.0ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.0ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.2ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.4ms\n","Speed: 3.2ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.3ms\n","Speed: 2.9ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.7ms\n","Speed: 3.5ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 7.8ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.1ms preprocess, 36.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 2.8ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.2ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.2ms preprocess, 36.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 2.9ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.4ms preprocess, 36.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.0ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 2.9ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.2ms preprocess, 35.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.1ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.3ms\n","Speed: 3.2ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.5ms\n","Speed: 3.5ms preprocess, 34.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.1ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.2ms\n","Speed: 3.6ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.1ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.0ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.7ms\n","Speed: 2.9ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.2ms preprocess, 36.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 8.0ms preprocess, 35.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.3ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.9ms\n","Speed: 3.1ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.2ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.6ms\n","Speed: 3.8ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.9ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.9ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 3.0ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 2.7ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.2ms\n","Speed: 3.6ms preprocess, 36.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.1ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.2ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.8ms preprocess, 36.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 33.9ms\n","Speed: 2.9ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.1ms preprocess, 35.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 5.0ms preprocess, 35.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.0ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.1ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 2.9ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.3ms\n","Speed: 3.7ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.0ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.6ms\n","Speed: 3.1ms preprocess, 38.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.4ms\n","Speed: 3.1ms preprocess, 38.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.5ms\n","Speed: 4.3ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.9ms\n","Speed: 3.0ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.1ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.1ms\n","Speed: 3.9ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.8ms preprocess, 36.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.5ms\n","Speed: 3.0ms preprocess, 37.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.4ms\n","Speed: 3.0ms preprocess, 38.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 38.2ms\n","Speed: 2.8ms preprocess, 38.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 3.2ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.0ms\n","Speed: 2.9ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.8ms\n","Speed: 3.1ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.4ms\n","Speed: 3.0ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.2ms\n","Speed: 3.0ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.4ms\n","Speed: 2.1ms preprocess, 37.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.5ms\n","Speed: 3.0ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.1ms preprocess, 36.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.0ms\n","Speed: 3.1ms preprocess, 37.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 40.5ms\n","Speed: 3.1ms preprocess, 40.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 37.4ms\n","Speed: 3.6ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 39.2ms\n","Speed: 3.0ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 39.9ms\n","Speed: 3.6ms preprocess, 39.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 39.4ms\n","Speed: 3.1ms preprocess, 39.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 3.1ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.7ms\n","Speed: 3.6ms preprocess, 35.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 36.6ms\n","Speed: 3.5ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.9ms\n","Speed: 3.9ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.8ms\n","Speed: 2.8ms preprocess, 34.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 34.2ms\n","Speed: 3.2ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 35.0ms\n","Speed: 4.2ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"]}]},{"cell_type":"code","source":["# Option 1: Save to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","csv_path = f'/content/drive/MyDrive/{framework_name}_execution_times.csv'\n","df.to_csv(csv_path, index=False)\n","print(f'Data saved to {csv_path}')\n","\n","# Option 2: Download the CSV file directly\n","df.to_csv(f'{framework_name}_execution_times.csv', index=False)\n","from google.colab import files\n","files.download(f'{framework_name}_execution_times.csv')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"DBtuO927FH_l","executionInfo":{"status":"ok","timestamp":1732284816252,"user_tz":-60,"elapsed":31124,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}},"outputId":"777b8800-583f-4089-f45b-bc42c99c0376"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Data saved to /content/drive/MyDrive/Supervision_execution_times.csv\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_8b0c69a9-1958-42fa-bde6-074e08cc4787\", \"Supervision_execution_times.csv\", 3012)"]},"metadata":{}}]},{"cell_type":"code","source":["res = detect(\"desk.jpg\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlzPonifzOXQ","executionInfo":{"status":"ok","timestamp":1732218867457,"user_tz":-60,"elapsed":3770,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}},"outputId":"b0f104a7-0066-4635-f304-3338677c4fdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 8 books, 3676.7ms\n","Speed: 4.2ms preprocess, 3676.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"]}]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","cv2_imshow(res)"],"metadata":{"id":"vTCccd9xzngE","executionInfo":{"status":"ok","timestamp":1732218877226,"user_tz":-60,"elapsed":2104,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}},"outputId":"85d98ff0-9bcd-4d07-afa2-bf5fc38cc75b","colab":{"base_uri":"https://localhost:8080/","height":865,"output_embedded_package_id":"1n2raPltBZ-VAg8kogjEg2cy0qxNvMMin"}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["%timeit detect(\"desk.jpg\")"],"metadata":{"id":"1lFwuzwszo1d","executionInfo":{"status":"ok","timestamp":1730986040463,"user_tz":-60,"elapsed":2369,"user":{"displayName":"Jon Cavallie Mester","userId":"11099483715591885036"}},"outputId":"add903b1-b351-4f46-95df-b4799eaa742f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 3 books, 1 vase, 203.1ms\n","Speed: 4.2ms preprocess, 203.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 3 books, 1 vase, 193.3ms\n","Speed: 5.5ms preprocess, 193.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 3 books, 1 vase, 197.8ms\n","Speed: 4.1ms preprocess, 197.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 3 books, 1 vase, 199.9ms\n","Speed: 5.6ms preprocess, 199.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 3 books, 1 vase, 184.9ms\n","Speed: 5.2ms preprocess, 184.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 3 books, 1 vase, 210.3ms\n","Speed: 4.9ms preprocess, 210.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 3 books, 1 vase, 202.1ms\n","Speed: 4.3ms preprocess, 202.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 cup, 2 potted plants, 1 tv, 1 mouse, 1 keyboard, 1 cell phone, 3 books, 1 vase, 200.8ms\n","Speed: 3.9ms preprocess, 200.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","276 ms ± 9.05 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"eeKDl-0_zs-n"},"execution_count":null,"outputs":[]}]}